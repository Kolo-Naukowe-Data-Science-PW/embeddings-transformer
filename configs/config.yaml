defaults:
  - _self_

train:
  max_seq_len: 2048
  embed_dim: 384
  nhead: 6
  num_layers: 4
  batch_size: 8
  epochs: 50
  learning_rate: 3e-4
  weight_decay: 0.01
  dropout: 0.2
  model_name: "embed_model"

dataset:
  tokenizer_path: "awesome.json"
  limit: None

wandb:
  project: "midi-embeddings"
  viz_interval: 2

device: "cuda"
seed: 42
